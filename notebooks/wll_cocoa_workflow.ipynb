{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1769120",
   "metadata": {},
   "source": [
    "\n",
    "# Cocoa Structural Break Workflow (WLL vs. ML)\n",
    "\n",
    "This notebook follows the workflow in the **WLL Cocoa Extension proposal** (hypothesis section omitted). It is designed so your supervisor can click **Run All** to reproduce the end-to-end experiment:\n",
    "\n",
    "1. Load the prepared cocoa + weather dataset\n",
    "2. Detect a single structural break (Mohr & Selk style search over split points)\n",
    "3. Fit pre-break and post-break local regressors\n",
    "4. Choose the WLL mixing weight `gamma` via Modified Forward Validation (MFV, Q=4)\n",
    "5. Compare against ML baselines (Random Forest, optional XGBoost)\n",
    "6. Report post-break MSFE and plot the forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e68763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick settings – no edits needed\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Tuple\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if not (ROOT / \"src\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "SRC_PATH = ROOT / \"src\"\n",
    "if SRC_PATH.exists():\n",
    "    os.chdir(ROOT)\n",
    "    sys.path.append(str(SRC_PATH))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    XGB_AVAILABLE = True\n",
    "except Exception:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "np.random.seed(42)\n",
    "DATA_PATH = Path(\"data/processed/cocoa_ghana_full.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load data (tries to build features if the CSV is missing)\n",
    "if not DATA_PATH.exists():\n",
    "    from cocoa.data.features import build_features\n",
    "    raw_dir = Path(\"data/raw\")\n",
    "    processed_dir = Path(\"data/processed\")\n",
    "    print(\"Processed file missing – building from raw inputs...\")\n",
    "    _ = build_features(raw_dir, processed_dir, reading_path='Ghana_data_full.csv', file_name=DATA_PATH.name)\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[\"date\"])\n",
    "# Keep only the columns we need for modeling\n",
    "feature_cols = [\n",
    "    \"PRCP_anom_mean\",\n",
    "    \"TAVG_anom_mean\",\n",
    "    \"PRCP_anom_std\",\n",
    "    \"TAVG_anom_std\",\n",
    "    \"N_stations\",\n",
    "    \"log_price_lagt\",\n",
    "]\n",
    "target_col = \"log_return_forecast_target\"\n",
    "print(f\"Loaded {len(df):,} observations with features: {feature_cols}\\nTarget: {target_col}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0957beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Helper: simple Mohr–Selk style break detection\n",
    "\n",
    "def detect_break_least_squares(series: pd.Series, trim: float = 0.1) -> int:\n",
    "    '''Return the index (0-based) that minimizes pre/post squared error.'''\n",
    "    y = series.values\n",
    "    T = len(y)\n",
    "    start = int(T * trim)\n",
    "    end = int(T * (1 - trim))\n",
    "    best_idx, best_score = start, np.inf\n",
    "    prefix_sum = np.cumsum(y)\n",
    "    prefix_sq = np.cumsum(y ** 2)\n",
    "\n",
    "    for k in range(start, end):\n",
    "        n1 = k\n",
    "        n2 = T - k\n",
    "        if n1 == 0 or n2 == 0:\n",
    "            continue\n",
    "        mean1 = prefix_sum[k-1] / n1\n",
    "        mean2 = (prefix_sum[-1] - prefix_sum[k-1]) / n2\n",
    "        sse1 = prefix_sq[k-1] - 2 * mean1 * prefix_sum[k-1] + n1 * mean1 ** 2\n",
    "        sse2 = (prefix_sq[-1] - prefix_sq[k-1]) - 2 * mean2 * (prefix_sum[-1] - prefix_sum[k-1]) + n2 * mean2 ** 2\n",
    "        total = sse1 + sse2\n",
    "        if total < best_score:\n",
    "            best_score = total\n",
    "            best_idx = k\n",
    "    return best_idx\n",
    "\n",
    "break_idx = detect_break_least_squares(df[target_col])\n",
    "break_date = df.loc[break_idx, \"date\"].date()\n",
    "print(f\"Estimated break date: {break_date} (index {break_idx})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Prepare train / validation / test splits\n",
    "\n",
    "df_sorted = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "pre_break = df_sorted.iloc[:break_idx]\n",
    "post_break = df_sorted.iloc[break_idx:]\n",
    "\n",
    "# Hold out the last 25% of post-break data for out-of-sample testing\n",
    "holdout_start = break_idx + int(len(post_break) * 0.75)\n",
    "train_df = df_sorted.iloc[:holdout_start]\n",
    "oos_df = df_sorted.iloc[holdout_start:]\n",
    "\n",
    "print(f\"Pre-break obs: {len(pre_break):,}\\nPost-break obs: {len(post_break):,}\\nOOS obs: {len(oos_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ab542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Define a lightweight local regressor (distance-weighted kNN)\n",
    "\n",
    "def make_local_regressor(n_neighbors: int = 25) -> Pipeline:\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"knn\", KNeighborsRegressor(n_neighbors=n_neighbors, weights=\"distance\")),\n",
    "    ])\n",
    "\n",
    "pre_model = make_local_regressor()\n",
    "post_model = make_local_regressor()\n",
    "\n",
    "pre_model.fit(pre_break[feature_cols], pre_break[target_col])\n",
    "post_model.fit(post_break.iloc[:-len(oos_df)][feature_cols], post_break.iloc[:-len(oos_df)][target_col])\n",
    "\n",
    "print(\"Trained pre-break and post-break local regressors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6daeb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Modified Forward Validation (Q=4) to pick gamma for WLL\n",
    "\n",
    "def mfv_gamma_search(\n",
    "    df_train: pd.DataFrame,\n",
    "    pre_pred: np.ndarray,\n",
    "    post_pred: np.ndarray,\n",
    "    y_true: np.ndarray,\n",
    "    Q: int = 4,\n",
    "    gamma_grid: np.ndarray | None = None,\n",
    ") -> Tuple[float, pd.DataFrame]:\n",
    "    if gamma_grid is None:\n",
    "        gamma_grid = np.linspace(0, 1, 11)\n",
    "\n",
    "    block_size = len(df_train) // Q\n",
    "    blocks = [(\n",
    "        i * block_size,\n",
    "        len(df_train) if i == Q - 1 else (i + 1) * block_size,\n",
    "    ) for i in range(Q)]\n",
    "\n",
    "    records = []\n",
    "    for gamma in gamma_grid:\n",
    "        fold_losses = []\n",
    "        for start, end in blocks:\n",
    "            if start == end:\n",
    "                continue\n",
    "            y_block = y_true[start:end]\n",
    "            pred_block = gamma * pre_pred[start:end] + (1 - gamma) * post_pred[start:end]\n",
    "            fold_losses.append(mean_squared_error(y_block, pred_block))\n",
    "        records.append({\"gamma\": gamma, \"mfv_msfe\": np.mean(fold_losses)})\n",
    "\n",
    "    results = pd.DataFrame(records).sort_values(\"mfv_msfe\")\n",
    "    best_gamma = float(results.iloc[0][\"gamma\"])\n",
    "    return best_gamma, results\n",
    "\n",
    "train_features = train_df[feature_cols]\n",
    "train_target = train_df[target_col].values\n",
    "\n",
    "pre_pred_train = pre_model.predict(train_features)\n",
    "post_pred_train = post_model.predict(train_features)\n",
    "\n",
    "best_gamma, gamma_table = mfv_gamma_search(train_df, pre_pred_train, post_pred_train, train_target)\n",
    "print(\"Best gamma (MFV):\", best_gamma)\n",
    "\n",
    "gamma_table.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d58af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Compute OOS predictions for WLL and components\n",
    "\n",
    "oos_features = oos_df[feature_cols]\n",
    "oos_target = oos_df[target_col].values\n",
    "\n",
    "pre_pred_oos = pre_model.predict(oos_features)\n",
    "post_pred_oos = post_model.predict(oos_features)\n",
    "wll_pred_oos = best_gamma * pre_pred_oos + (1 - best_gamma) * post_pred_oos\n",
    "\n",
    "print(\"Preview of OOS predictions (first 5 rows):\")\n",
    "pd.DataFrame({\n",
    "    \"date\": oos_df[\"date\"].head(5),\n",
    "    \"y_true\": oos_target[:5],\n",
    "    \"pre\": pre_pred_oos[:5],\n",
    "    \"post\": post_pred_oos[:5],\n",
    "    \"wll\": wll_pred_oos[:5],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc99d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) ML baselines\n",
    "\n",
    "ml_predictions = {}\n",
    "\n",
    "rf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"rf\", RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1))\n",
    "])\n",
    "rf.fit(train_features, train_target)\n",
    "ml_predictions[\"Random Forest\"] = rf.predict(oos_features)\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=400,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        objective=\"reg:squarederror\",\n",
    "    )\n",
    "    xgb.fit(train_features, train_target)\n",
    "    ml_predictions[\"XGBoost\"] = xgb.predict(oos_features)\n",
    "else:\n",
    "    print(\"XGBoost not available in this environment – skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c988bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "models_to_show = {\n",
    "    \"Pre-Break Local\": pre_pred_oos,\n",
    "    \"Post-Break Local\": post_pred_oos,\n",
    "    \"Weighted LL (MFV)\": wll_pred_oos,\n",
    "    **ml_predictions,\n",
    "}\n",
    "\n",
    "for name, preds in models_to_show.items():\n",
    "    msfe = mean_squared_error(oos_target, preds)\n",
    "    results.append({\"Model\": name, \"Post-break MSFE\": msfe})\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"Post-break MSFE\")\n",
    "print(\"Post-break MSFE (lower is better):\")\n",
    "print(results_df)\n",
    "\n",
    "# Plot the best two models\n",
    "best_two = results_df.head(2)[\"Model\"].tolist()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(oos_df[\"date\"], oos_target, label=\"Actual\", color=\"black\", linewidth=2)\n",
    "for name in best_two:\n",
    "    plt.plot(oos_df[\"date\"], models_to_show[name], label=name, linewidth=2)\n",
    "plt.axvline(oos_df[\"date\"].iloc[0], color=\"red\", linestyle=\"--\", label=\"OOS start\")\n",
    "plt.title(\"Post-break forecasts vs. actual returns\")\n",
    "plt.ylabel(\"Next-day log return\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad96a5",
   "metadata": {},
   "source": [
    "\n",
    "## How to use\n",
    "\n",
    "1. Open this notebook in Jupyter or VS Code.\n",
    "2. Click **Run All** – the cells load the data, detect the break, fit all models, and plot results.\n",
    "3. The `results_df` table reports post-break MSFE so you can compare WLL against the ML baselines.\n",
    "\n",
    "_No manual parameter tuning is required._\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
