{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10796ff4",
   "metadata": {},
   "source": [
    "# Cocoa price forecasting workflow (supervisor-ready)\n",
    "\n",
    "This notebook follows the workflow outlined in the **WLL Cocoa Extension** proposal (hypothesis section intentionally omitted). Every step is arranged so you can run cells from top to bottom without editing code. The only requirement is that the repository dependencies are installed (see `requirements.txt`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd45ee7",
   "metadata": {},
   "source": [
    "## 1. Quick start\n",
    "\n",
    "1. Ensure the virtual environment is active and dependencies are installed: `pip install -r requirements.txt`.\n",
    "2. Open this notebook (`notebooks/wll_cocoa_extension.ipynb`).\n",
    "3. Click **Run All** in Jupyter. The notebook will load the processed dataset, train two quick baseline models, and produce plots.\n",
    "\n",
    "All paths are pre-filled for the checked-in processed dataset (`data/processed/cocoa_ghana_full.csv`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccec6f8",
   "metadata": {},
   "source": [
    "## 2. Imports and settings\n",
    "\n",
    "- Adjust `OOS_START_DATE` only if you want to change the out-of-sample window.\n",
    "- The feature and target lists are defined to match the processed data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b93bff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(SRC_DIR) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys.path:\n\u001b[32m     20\u001b[39m     sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(SRC_DIR))\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcocoa\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RFModel, XGBModel\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Plotting style\u001b[39;00m\n\u001b[32m     25\u001b[39m plt.style.use(\u001b[33m'\u001b[39m\u001b[33mseaborn-v0_8\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mW:\\Research\\NP\\Cocoa\\src\\cocoa\\models\\__init__.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_forecast\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnp_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseKernel, BaseLocalEngine\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnp_kernels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GaussianKernel, EpanechnikovKernel\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnp_engines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LocalPolynomialEngine\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcombo_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseConvexCombinationModel\n",
      "\u001b[36mFile \u001b[39m\u001b[32mW:\\Research\\NP\\Cocoa\\src\\cocoa\\models\\np_kernels.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnp_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseKernel\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mGaussianKernel\u001b[39;00m(BaseKernel):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    \"\"\"Walk up the tree until we find the project marker (pyproject).\"\"\"\n",
    "    for candidate in (start, *start.parents):\n",
    "        if (candidate / \"pyproject.toml\").exists():\n",
    "            return candidate\n",
    "    return start\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root(Path.cwd().resolve())\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "from cocoa.models.ml_models import RFModel, XGBModel\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / 'data' / 'processed' / 'cocoa_ghana_full.csv'\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Processed dataset not found at {DATA_PATH}. \"\n",
    "        \"Re-run the feature pipeline or update DATA_PATH.\"\n",
    "    )\n",
    "\n",
    "# Start date for out-of-sample evaluation\n",
    "OOS_START_DATE = '2023-01-01'\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    'PRCP_anom_mean', 'TAVG_anom_mean', 'PRCP_anom_std', 'TAVG_anom_std',\n",
    "    'N_stations', 'log_price_lagt', 'log_return'\n",
    "]\n",
    "TARGET_COL = 'log_return_forecast_target'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c23ea",
   "metadata": {},
   "source": [
    "## 3. Load and inspect the processed dataset\n",
    "\n",
    "The cell below reads the processed Ghana cocoa panel, shows a preview, and reports the coverage period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d56705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, parse_dates=['date'])\n",
    "print(f\"Rows: {len(df):,} | Columns: {list(df.columns)}\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nDate range: {df['date'].min().date()} to {df['date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1602504d",
   "metadata": {},
   "source": [
    "## 4. Visualize price levels and returns\n",
    "\n",
    "Two quick plots help confirm that the data load is working:\n",
    "- Log price trend\n",
    "- One-step-ahead log returns (target variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d26ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "axes[0].plot(df['date'], df['log_price'], label='Log price', color='navy')\n",
    "axes[0].set_ylabel('Log price')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(df['date'], df[TARGET_COL], label='Target log return', color='darkorange')\n",
    "axes[1].axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "axes[1].set_ylabel('Log return target')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01db7ff0",
   "metadata": {},
   "source": [
    "## 5. Train/test split\n",
    "\n",
    "The split uses a calendar cut: everything before `OOS_START_DATE` is training data; later observations are held out for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ba72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = df['date'] < pd.to_datetime(OOS_START_DATE)\n",
    "test_mask = ~train_mask\n",
    "\n",
    "train_df = df.loc[train_mask].copy()\n",
    "test_df = df.loc[test_mask].copy()\n",
    "\n",
    "X_train, y_train = train_df[FEATURE_COLS], train_df[TARGET_COL]\n",
    "X_test, y_test = test_df[FEATURE_COLS], test_df[TARGET_COL]\n",
    "\n",
    "print(f\"Training rows: {len(X_train):,}\")\n",
    "print(f\"Test rows: {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b88ae38",
   "metadata": {},
   "source": [
    "## 6. Fit quick baseline models\n",
    "\n",
    "Two models are run for comparison:\n",
    "- **Random Forest**: fast nonlinear benchmark.\n",
    "- **XGBoost**: gradient-boosted trees with modest parameters for quick execution.\n",
    "\n",
    "Hyperparameters are intentionally lightweight so the notebook remains \"click-and-run\" friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11bc6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RFModel(n_estimators=200, max_features=0.6, min_samples_leaf=2, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "xgb = XGBModel(\n",
    "    n_estimators=250,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f030b90",
   "metadata": {},
   "source": [
    "## 7. Evaluate and compare\n",
    "\n",
    "Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) are reported for the out-of-sample period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_metrics(name, y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    return {'model': name, 'MAE': mae, 'RMSE': rmse}\n",
    "\n",
    "results = [\n",
    "    summarize_metrics('Random Forest', y_test, rf_pred),\n",
    "    summarize_metrics('XGBoost', y_test, xgb_pred),\n",
    "]\n",
    "\n",
    "metrics_df = pd.DataFrame(results)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ae102",
   "metadata": {},
   "source": [
    "## 8. Plot forecasts vs. actuals\n",
    "\n",
    "The chart below overlays the two model forecasts against the target series for the evaluation window. A horizontal line at zero helps spot direction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(test_df['date'], y_test, label='Actual target', color='black', linewidth=2)\n",
    "ax.plot(test_df['date'], rf_pred, label='Random Forest forecast', color='teal', alpha=0.8)\n",
    "ax.plot(test_df['date'], xgb_pred, label='XGBoost forecast', color='crimson', alpha=0.8)\n",
    "ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "ax.set_ylabel('Log return target')\n",
    "ax.set_xlabel('Date')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8d18cf",
   "metadata": {},
   "source": [
    "## 9. Save quick-look outputs (optional)\n",
    "\n",
    "If you want to keep the evaluation numbers and plot, uncomment the save lines below. Files will be written under `reports/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save outputs\n",
    "# output_dir = PROJECT_ROOT / 'reports'\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# metrics_df.to_csv(output_dir / 'wll_click_run_metrics.csv', index=False)\n",
    "# fig_path = output_dir / 'wll_click_run_forecast.png'\n",
    "# plt.savefig(fig_path, dpi=200)\n",
    "# print(f\"Saved metrics and plot to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
